CODE FROM Gustavo Trigo (Gustrigos) 


import math
import pandas as pd
import numpy as np
import datetime as dt
import matplotlib.pyplot as plt
from matplotlib import style
import seaborn as sns
from scipy.stats import randint as sp_randint

from sklearn.decomposition import PCA

style.use("ggplot")

# loading the data
df = pd.read_csv('SP500_adjcloses.csv', parse_dates=True, index_col=0)

# Getting rid of non-business days
df.dropna(how='all', inplace=True)

# Dimension of the data set
print('Data frame shape', df.shape)

# Getting rid of stocks without enough data points
df.drop([
    'BHGE', 'BHF', 'CBRE', 'DWDP', 
    'DXC', 'EVRG', 'FTV', 'HPE', 
    'KHC', 'PYPL', 'QRVO', 'UA'
    ], axis=1, inplace=True)

# Copying the dataframe to add features
data = pd.DataFrame(df.copy())

# Daily Linear Returns (%)
datareturns = data.pct_change(1)

# Data Raw
data_raw = datareturns
data_raw.dropna(how='all', inplace=True)

# Normalizing the Linear returns
data = (data_raw - data_raw.mean()) / data_raw.std()

# Visualizing Linear Returns for the SP500 
# plt.figure(figsize=(16, 5))
# plt.title("S&P 500 Linear Returns (%)")
# data.SP500.plot()
# plt.grid(True);
# plt.legend()
# plt.show()

# Taking away the market benchmark SP500
stock_tickers = data.columns.values[:-1]
n_tickers = len(stock_tickers)
cov_matrix = pd.DataFrame(data=np.ones(shape=(n_tickers, n_tickers)), columns=stock_tickers) 
cov_matrix_raw = cov_matrix

# Dividing the dataset into training and testing sets

train_end = dt.datetime(2017,9,20)
X_train = data[data.index <= train_end].copy()
X_test = data[data.index > train_end].copy()
X_train_raw = data_raw[data_raw.index <= train_end].copy()
X_test_raw = data_raw[data_raw.index > train_end].copy()

print('Training size:', X_train.shape)
print('Testing size:', X_test.shape)

# Creating a variance-covariance matrix 
cov_matrix = X_train.loc[:,X_train.columns != 'SP500'].cov()
cov_matrix_raw = X_train_raw.loc[:,X_train_raw.columns != 'SP500'].cov()
cov_raw_data = pd.DataFrame({'Variance': np.diag(cov_matrix_raw)}, index=stock_tickers)

# Applying Principle Component Analysis
pca = PCA()
pca.fit(cov_matrix)

def plotPCA(plot=False):

    # Visualizing Variance against number of principal components.

    var_threshold = 0.95
    var_explained = np.cumsum(pca.explained_variance_ratio_)
    num_comp = np.where(np.logical_not(var_explained < var_threshold))[0][0] + 1  

    if plot:
        print('%d principal components explain %.2f%% of variance' %(num_comp, 100* var_threshold))

        # PCA percent variance explained.
        bar_width = 0.9
        n_asset = stock_tickers.shape[0]
        x_indx = np.arange(n_asset)
        fig, ax = plt.subplots()

        # Eigenvalues measured as percentage of explained variance.
        rects = ax.bar(x_indx, pca.explained_variance_ratio_[:n_asset], bar_width)
        ax.set_xticks(x_indx + bar_width / 2)
        ax.set_xticklabels(list(range(n_asset)), rotation=45)
        ax.set_title('Percent variance explained')
        ax.set_ylabel('Explained Variance')
        ax.set_xlabel('Principal Components')
        plt.show()

    return num_comp

pc_num = plotPCA()

plotPCA(plot=True)

projected = pca.fit_transform(cov_matrix)
pcs = pca.components_

# Sharpe Ratio
def sharpe_ratio(ts_returns, periods_per_year=252):
    '''
    Sharpe ratio is the average return earned in excess of the risk-free rate per unit of volatility or total risk.
    It calculares the annualized return, annualized volatility, and annualized sharpe ratio.
    
    ts_returns are returns of a single eigen portfolio.
    '''
    n_years = ts_returns.shape[0]/periods_per_year
    annualized_return = np.power(np.prod(1+ts_returns),(1/n_years))-1
    annualized_vol = ts_returns.std() * np.sqrt(periods_per_year)
    annualized_sharpe = annualized_return / annualized_vol

    return annualized_return, annualized_vol, annualized_sharpe

def optimizedPortfolio(plot=False):
    n_portfolios = pc_num
    annualized_ret = np.array([0.] * n_portfolios)
    sharpe_metric = np.array([0.] * n_portfolios)
    annualized_vol = np.array([0.] * n_portfolios)
    idx_highest_sharpe = 0 

    for i in range(n_portfolios):
        
        pc_w = pcs[:, i] / sum(pcs[:, i])
        eigen_prtfi = pd.DataFrame(data ={'weights': pc_w.squeeze()*100}, index = stock_tickers)
        eigen_prtfi.sort_values(by=['weights'], ascending=False, inplace=True)
        
        eigen_prti_returns = np.dot(X_test_raw.loc[:, eigen_prtfi.index], eigen_prtfi / 100)
        eigen_prti_returns = pd.Series(eigen_prti_returns.squeeze(), index=X_test.index)
        returns, vol, sharpe = sharpe_ratio(eigen_prti_returns)
        annualized_ret[i] = returns
        annualized_vol[i] = vol
        sharpe_metric[i] = sharpe

    # find portfolio with the highest Sharpe ratio
    idx_highest_sharpe = np.nanargmax(sharpe_metric)

    print('Eigen portfolio #%d with the highest Sharpe. Return %.2f%%, vol = %.2f%%, Sharpe = %.2f' % 
          (idx_highest_sharpe,
           annualized_ret[idx_highest_sharpe]*100, 
           annualized_vol[idx_highest_sharpe]*100, 
           sharpe_metric[idx_highest_sharpe]))

    if plot:
        fig, ax = plt.subplots()
        fig.set_size_inches(12, 4)
        ax.plot(sharpe_metric, linewidth=3)
        ax.set_title('Sharpe ratio of eigen-portfolios')
        ax.set_ylabel('Sharpe ratio')
        ax.set_xlabel('Portfolios')

        results = pd.DataFrame(data={'Return': annualized_ret, 'Vol': annualized_vol, 'Sharpe': sharpe_metric})
        results.dropna(inplace=True)
        results.sort_values(by=['Sharpe'], ascending=False, inplace=True)
        print(results.head(10))

        plt.show()

optimizedPortfolio(plot=True)

def PCWeights():
    '''
    Principal Components (PC) weights for each explained PC
    '''
    weights = pd.DataFrame()

    for i in range(pc_num):
        weights["weights_{}".format(i)] = pcs[:, i] / sum(pcs[:, i])

    weights = weights.values.T
    return weights

weights = PCWeights()
portfolio = pd.DataFrame()

def plotEigen(weights, plot=False, portfolio=portfolio):
    portfolio = pd.DataFrame(data ={'weights': weights.squeeze()*100}, index = stock_tickers) 
    portfolio.sort_values(by=['weights'], ascending=False, inplace=True)
    
    if plot:
        print('Sum of weights of current eigen-portfolio: %.2f' % np.sum(portfolio))
        portfolio.plot(title='Current Eigen-Portfolio Weights', 
            figsize=(12,6), 
            xticks=range(0, len(stock_tickers),10), 
            rot=45, 
            linewidth=3
            )
        plt.show()

    return portfolio

# Weights are stored in arrays, where 0 is the first PC's weights.
plotEigen(weights=weights[33], plot=True)

def plotSharpe(eigenprt, plot=True):

    '''

    Plots Principle components returns against real returns.
    
    '''
    if plot:
        eigen_portfolio_returns = np.dot(X_test_raw.loc[:, eigenprt.index], eigenprt / 100)
        eigen_portfolio_returns = pd.Series(eigen_portfolio_returns.squeeze(), index=X_test.index)
        returns, vol, sharpe = sharpe_ratio(eigen_portfolio_returns)
        print('Current Eigen-Portfolio:\nReturn = %.2f%%\nVolatility = %.2f%%\nSharpe = %.2f' % (returns*100, vol*100, sharpe))
        year_frac = (eigen_portfolio_returns.index[-1] - eigen_portfolio_returns.index[0]).days / 252

        data_plot = pd.DataFrame({'PC': eigen_portfolio_returns, 'SP500': X_test_raw.loc[:, 'SP500']}, index=X_test.index)
        np.cumprod(data_plot + 1).plot(title='Returns of the market-cap weighted index vs. First eigen-portfolio', 
                                 figsize=(12,6), linewidth=3)
        plt.show()

plotSharpe(eigenprt=plotEigen(weights=weights[33]), plot=True)


# Correlation matrix

def data_correlation():
    df_corr = df.corr()
    print(df_corr.head())

    data = df_corr.values
    fig = plt.figure()
    ax = fig.add_subplot(1,1,1)

    # heatmap consists of Red Yellow and Green 
    heatmap = ax.pcolor(data, cmap=plt.cm.RdYlGn)
    fig.colorbar(heatmap)
    ax.set_xticks(np.arange(data.shape[0]) + 0.5, minor=False)
    ax.set_yticks(np.arange(data.shape[1]) + 0.5, minor=False)
    ax.invert_yaxis()
    ax.xaxis.tick_top()
    column_labels = df_corr.columns
    row_labels = df_corr.index

    ax.set_xticklabels(column_labels)
    ax.set_yticklabels(row_labels)
    plt.xticks(rotation=90)
    heatmap.set_clim(-1,1)
    plt.tight_layout()
    plt.show()

data_correlation()
